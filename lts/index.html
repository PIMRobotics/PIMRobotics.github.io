<!doctype html>
<html lang="en">


<!-- === Header Starts === -->
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Locate then Segment: A Strong Pipeline for Referring Image Segmentation</title>

  <link href="./assets/bootstrap.min.css" rel="stylesheet">
  <link href="./assets/font.css" rel="stylesheet" type="text/css">
  <link href="./assets/style.css" rel="stylesheet" type="text/css">
</head>
<!-- === Header Ends === -->


<body>

<!-- === Home Section Starts === -->
<div class="section">
  <!-- === Title Starts === -->
  <div class="header">
    <div class="title", style="padding-top: 25pt;">  <!-- Set padding as 10 if title is with two lines. -->
      Locate then Segment: A Strong Pipeline for Referring Image Segmentation
    </div>
  </div>
  <!-- === Title Ends === -->
  <div class="author">
      <a href="https://jingyaa.github.io/jingya.github.io">Ya Jing</a><sup>1</sup>,&nbsp;
    <a href="http://www.taokong.org">Tao Kong</a><sup>2</sup>,&nbsp;
    <a href="http://www.nlpr.ia.ac.cn/users/wangwei1/index.htm">Wei Wang</a><sup>1</sup>,&nbsp;
      <a href="http://www.cbsr.ia.ac.cn/users/liangwang/">Liang Wang</a><sup>2</sup>,&nbsp;
      <a href="https://lileicc.github.io">Lei Li</a><sup>2</sup>,
      <a href="http://www.cbsr.ia.ac.cn/users/tnt/tnt.htm">Tieniu Tan</a><sup>2</sup>,
  </div>
  <div class="institution">
      <sup>1</sup>Chinese Academy of Sciences,&nbsp;&nbsp;&nbsp;
      <sup>2</sup>ByteDance AI Lab
  </div>
  <div class="link">
    <a href="https://arxiv.org/abs/2103.16284">[Paper]</a>&nbsp;
    <a href="https://mp.weixin.qq.com/s/jqDqybXe5isQZvx9dcAAnw">[Post]</a>
  </div>

    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
        <td><img src="files/lts.png" width="70%"></td>
      </tr>
    </table>

</div>
<!-- === Home Section Ends === -->


<!-- === Overview Section Starts === -->
<div class="section">
  <div class="title">Overview</div>
  <div class="body">
    Referring image segmentation aims to segment the objects referred by a natural language expression.
    In this work, we view this task from the perspective of decoupling it into a "Locate-Then-Segment" (LTS) scheme.
    Given a language expression, people generally first perform attention to the corresponding target image regions,
    then generate a fine segmentation mask about the object based on its context.
    The LTS first extracts and fuses both visual and textual features to get a cross-modal representation,
    then applies a cross-model interaction on the visual-textual features to locate the referred object with position prior,
    and finally generates the segmentation result with a light-weight segmentation network.
    Our LTS is simple but surprisingly effective. On three popular benchmark datasets,
    the LTS outperforms all the previous state-of-the-art methods by a large margin (e.g., +3.2% on RefCOCO+ and +3.4% on RefCOCOg).
    In addition, our model is more interpretable with explicitly locating the object, which is also proved by visualization experiments.

  </div>
</div>
<!-- === Overview Section Ends === -->


<!-- === Result Section Starts === -->
<div class="section">
  <div class="title">Visualization</div>
  <div class="body">
      Visualization of correlation heatmaps and final results predicted by our model.
    gt means the ground truth segmentation mask of input image.
    <!-- Adjust the number of rows and columns (EVERY project differs). -->
    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
        <td><img src="files/vis.png" width="80%"></td>
      </tr>
    </table>


<!--      -->
<!--    Demo video here.-->
<!--    &lt;!&ndash; Adjust the frame size based on the demo (EVERY project differs). &ndash;&gt;-->
<!--    <div style="position: relative; padding-top: 50%; margin: 20pt 0; text-align: center;">-->
<!--      <iframe src="https://via.placeholder.com/900x450" frameborder=0-->
<!--              style="position: absolute; top: 2.5%; left: 2.5%; width: 95%; height: 100%;"-->
<!--              allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"-->
<!--              allowfullscreen></iframe>-->
<!--    </div>-->
  </div>
</div>
<!-- === Result Section Ends === -->


<!-- === Reference Section Starts === -->
<div class="section">
  <div class="bibtex">BibTeX</div>
<pre>
@inproceedings{jing2020lts,
  title={Locate then Segment: A Strong Pipeline for Referring Image Segmentation},
  author={Jing, Ya and Kong, Tao and Wang, Wei and Wang, Liang and Li, Lei and Tan, Tieniu},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

</pre>
</div>

</body>

</html>